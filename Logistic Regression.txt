
bin/spark-shell --master yarn-client  --executor-memory 2g

val rawData = sc.textFile("/ML/classf/train_noheader.tsv")

val records = rawData.map(x => x.split("\t"))


import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.linalg.Vectors

val data = records.map {r =>
 val trimmed = r.map(_.replaceAll("\"",""))
 val label = trimmed(r.size-1).toInt
 val features = trimmed.slice(4,r.size-1).map(d => if(d=="?")0.0 else d.toDouble)
 LabeledPoint(label,Vectors.dense(features))
}

val datanums = data.count

import org.apache.spark.mllib.classification.LogisticRegressionWithSGD
val numIterations = 10

val lrModel = LogisticRegressionWithSGD.train(data,numIterations)

lrModel.clearThreshold()

 
val lrTotalCorrect = data.map {point => if (lrModel.predict(point.features)==point.label) 1 else 0
 }.sum
val lrAccuracy = lrTotalCorrect/datanums



import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics
val metrics = Seq(lrModel).map{model =>
  val scoreAndLabels = data.map{point => 
   (model.predict(point.features),point.label)
  }
  val metrics = new BinaryClassificationMetrics(scoreAndLabels)
    (model.getClass.getSimpleName,metrics.areaUnderPR,metrics.areaUnderROC)
  }

metrics.foreach {case (m,pr,roc) =>
 println(f"$m, Area Under PR: ${pr*100.0}%2.4f%%,Area Under ROC: ${roc*100.0}%2.4f%%")}



import org.apache.spark.mllib.linalg.distributed.RowMatrix
val vectors = data.map(lp => lp.features)
val matrix = new RowMatrix(vectors)
val matrixSummary = matrix.computeColumnSummaryStatistics()


println(matrixSummary.mean)
println(matrixSummary.min)
println(matrixSummary.max)
println(matrixSummary.variance)
println(matrixSummary.numNonzeros)


import org.apache.spark.mllib.feature.StandardScaler
val scaler = new StandardScaler(withMean=true,withStd = true).fit(vectors)
val scaledData = data.map(lp => LabeledPoint(lp.label,scaler.transform(lp.features)))

println(data.first.features)
println(scaledData.first.features)


val lrModelScaled = LogisticRegressionWithSGD.train(scaledData,numIterations)

val lrTotalCorrectScaled = scaledData.map{point =>
  if(lrModelScaled.predict(point.features)==point.label) 1 else 0}.sum

val lrAccuracyScaled = lrTotalCorrectScaled/datanums
















